{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from custom files\n",
    "from dataset import CompCarsImageFolder, WrapperDataset\n",
    "from models import ResNet, resnet_cfg\n",
    "from models import train, validate\n",
    "from utils import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Configuration"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "###### Set root to the image folder of CompCars dataset ######\n",
    "\n",
    "#TODO: ADAPT TO YOUR FOLDER STRUCTURE\n",
    "root = '/Volumes/EDO/NNDL/CompCars dataset/data/image/'\n",
    "\n",
    "#############################################################\n",
    "\n",
    "### Hyperparam configuration # TODO: TUNE\n",
    "params = {                  ## Training Params (inspired from original resnet paper: https://arxiv.org/pdf/1512.03385)\n",
    "    'epoch_num': 50,        # number of epochs\n",
    "    'lr': 1e-1,             # (initial) Learning Rate\n",
    "    'weight_decay': 1e-4,   # L2 Penalty\n",
    "    'batch_size': 64,       # batch size (depends on hardware)\n",
    "    'momentum': 0.9,\n",
    "    \n",
    "    'hierarchy': 0,         # Choose 0 for manufacturer classification, 1 for model classification\n",
    "    'val_split': 10000,     # (float) Fraction of validation holdout / (int) Absolute number of data points in holdout\n",
    "    \n",
    "    'resnet': resnet_cfg['resnet18']  # Resnet model used\n",
    "}\n",
    "\n",
    "### Device\n",
    "if torch.cuda.is_available():\n",
    "    params[\"device\"] = torch.device(\"cuda\")   # option for NVIDIA GPUs\n",
    "elif torch.backends.mps.is_available():\n",
    "    params[\"device\"] = torch.device(\"mps\")    # option for Mac M-series chips (GPUs)\n",
    "else:\n",
    "    params[\"device\"] = torch.device(\"cpu\")    # default option if none of the above devices are available\n",
    "\n",
    "print(\"Device: {}\".format(params[\"device\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "\n",
    "## Read total Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# hierarchy=0 -> manufacturer classification; hierarchy=1 -> model classification\n",
    "total_set = CompCarsImageFolder(root, hierarchy=params['hierarchy'])\n",
    "print(total_set.classes)\n",
    "print(len(total_set.classes))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualization of the dataset\n",
    "label_dict = {y: x for x, y in total_set.class_to_idx.items()}\n",
    "\n",
    "num_images_to_show = 15\n",
    "data_idx = np.random.randint(0, high=len(total_set), size=num_images_to_show)\n",
    "num_cols = 5\n",
    "num_rows = num_images_to_show // num_cols\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 3))\n",
    "axes = axes.flatten()\n",
    "for i in range(num_images_to_show):\n",
    "    image, label = total_set[data_idx[i]]\n",
    "    npimg = np.array(image)\n",
    "    axes[i].imshow(npimg)\n",
    "    axes[i].set_title(label_dict[label])\n",
    "    axes[i].axis('off')\n",
    "    print(f\"Image shape: {image.size}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split in training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "datasets = train_val_dataset(total_set, val_split=params['val_split'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute normalization statistics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "'''\n",
    "NOTE: This cell takes some time. Could be accelerated by:\n",
    "    1. Using dataloader (vectorized batches)\n",
    "    2. Resize images before computing statistics\n",
    "'''\n",
    "# Default values (taken from the results from this cell)\n",
    "mean, std = [0.483, 0.471, 0.463], [0.297, 0.296, 0.302]\n",
    "\n",
    "# Compute mean and std for training dataset\n",
    "# train_mean, train_std = compute_mean_std_from_dataset(datasets['train'])\n",
    "# print(f\"Training dataset mean: {train_mean}\")\n",
    "# print(f\"Training dataset std: {train_std}\")\n",
    "train_mean, train_std = mean, std\n",
    "\n",
    "# Compute mean and std for validation dataset\n",
    "# val_mean, val_std = compute_mean_std_from_dataset(datasets['val'])\n",
    "# print(f\"Validation dataset mean: {val_mean}\")\n",
    "# print(f\"Validation dataset std: {val_std}\")\n",
    "val_mean, val_std = mean, std"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data - Prepare DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Apply transformation\n",
    "########################## Transforms ############################\n",
    "# TODO: Adapt transforms to our data set\n",
    "# TODO: maybe use v2 transforms: https://pytorch.org/vision/stable/transforms.html\n",
    "\n",
    "# inspired from https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "data_transforms = { # TODO: TUNE\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomChoice([\n",
    "            transforms.Resize(256),\n",
    "            transforms.Resize(224),\n",
    "            transforms.Resize(320)\n",
    "        ]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(train_mean, train_std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(val_mean, val_std)\n",
    "    ])\n",
    "}\n",
    "##################################################################\n",
    "\n",
    "wrapped_datasets = {\n",
    "    'train': WrapperDataset(datasets['train'], transform=data_transforms['train']),\n",
    "    'val': WrapperDataset(datasets['val'], transform=data_transforms['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(wrapped_datasets['train'], batch_size=params['batch_size'], shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(wrapped_datasets['val'], batch_size=params['batch_size'], shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"Total dataset size: {len(total_set)}\")\n",
    "print(f\"Training dataset size: {len(datasets['train'])}\")\n",
    "print(f\"Validation dataset size: {len(datasets['val'])}\")\n",
    "\n",
    "x, y = next(iter(dataloaders['train']))\n",
    "print(f\"Batch of training images shape: {x.shape}\")\n",
    "print(f\"Batch of training labels shape: {y.shape}\")\n",
    "\n",
    "x, y = next(iter(dataloaders['val']))\n",
    "print(f\"Batch of validation images shape: {x.shape}\")\n",
    "print(f\"Batch of validation labels shape: {y.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set up resnet model\n",
    "resnet = ResNet(params['resnet']['block'], params['resnet']['layers'], \n",
    "                len(total_set.classes)).to(params['device'])\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD( #SGD used in original resnet paper # TODO: TUNE\n",
    "    resnet.parameters(), \n",
    "    lr=params['lr'], \n",
    "    weight_decay=params['weight_decay'], \n",
    "    momentum=params['momentum']\n",
    ")\n",
    "\n",
    "# LR scheduler (using Top-1-Accuracy as Validation metric)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, min_lr=1e-5, patience=1, threshold=1e-2) # TODO: TUNE\n",
    "\n",
    "# Save performance metrics\n",
    "train_losses, validation_losses, train_acc, validation_acc, train_top5_acc, validation_top5_acc = list(), list(), list(), list(), list(), list()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "To start from checkpoint, set `START_FROM_CHECKPOINT=True`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CHECKPOINT_PATH = './training_checkpoints/checkpoint.pth'\n",
    "START_FROM_CHECKPOINT = False   # set to TRUE to start from checkpoint\n",
    "start_epoch = 0\n",
    "\n",
    "if START_FROM_CHECKPOINT:\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    resnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    train_losses = checkpoint['train_losses']\n",
    "    train_acc = checkpoint['train_acc']\n",
    "    train_top5_acc = checkpoint['train_top5_acc']\n",
    "    validation_losses = checkpoint['validation_losses']\n",
    "    validation_acc = checkpoint['validation_acc']\n",
    "    validation_top5_acc = checkpoint['validation_top5_acc']\n",
    "\n",
    "# Just some fancy progress bars # FIXME: inside epoch progress bar not working reliably for me\n",
    "pbar_epoch = trange(start_epoch, params[\"epoch_num\"], initial=start_epoch, desc=\"Training\", position=0)\n",
    "pbar_inside_epoch = trange(0, (len(dataloaders['train'])+len(dataloaders['val'])), desc=\"Training and validation per epoch\", position=1, leave=False)\n",
    "\n",
    "# Stop the training phase in case there is no improvement\n",
    "# early_stopper = EarlyStopper(patience=10, min_delta=0.1)\n",
    "\n",
    "for epoch in pbar_epoch:\n",
    "    pbar_inside_epoch.reset()\n",
    "\n",
    "    # Training\n",
    "    train_results = train(dataloaders['train'], resnet, epoch, criterion, optimizer, params[\"device\"], pbar=pbar_inside_epoch)\n",
    "    train_losses.append(train_results[0])\n",
    "    train_acc.append(1 - train_results[1])                 # saving acc error\n",
    "    train_top5_acc.append(1 - train_results[2])\n",
    "\n",
    "    # Validation\n",
    "    validation_results = validate(dataloaders['val'], resnet, epoch, criterion, params[\"device\"], pbar=pbar_inside_epoch)\n",
    "    validation_losses.append(validation_results[0])\n",
    "    validation_acc.append(1 - validation_results[1])       # saving acc error\n",
    "    validation_top5_acc.append(1 - validation_results[2])\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler.step(validation_results[1])   # ReduceLROnPlateau scheduler (reduce LR by 10 when top-1-accuracy does not improve)\n",
    "    print(f\"\\nCurrent Learning Rate: {scheduler._last_lr}\\n\")\n",
    "\n",
    "    # Checkpoint\n",
    "    torch.save({\n",
    "        'epoch' : epoch + 1,\n",
    "        'model_state_dict' : resnet.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict' : scheduler.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'train_acc': train_acc,\n",
    "        'train_top5_acc': train_top5_acc,\n",
    "        'validation_losses': validation_losses,\n",
    "        'validation_acc': validation_acc,\n",
    "        'validation_top5_acc': validation_top5_acc,\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "    # Comment on the following lines if you don't want to stop early in case of no improvement\n",
    "    # if early_stopper.early_stop(validation_results[0]):\n",
    "    #     params['epoch_num'] = epoch\n",
    "    #     print(\"\\n\\nEarly stopping...\")\n",
    "    #     break\n",
    "\n",
    "pbar_inside_epoch.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plotting the performance of the model in the training and validation phase\n",
    "\n",
    "params[\"epoch_num\"] = 39\n",
    "\n",
    "plots = [\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), train_losses, \"Train Loss\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), validation_losses, \"Validation Loss\")\n",
    "]\n",
    "\n",
    "show_plot(plots, \"Model Loss for Epoch\", \"Epoch\", \"Loss\")\n",
    "\n",
    "plots = [\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), train_acc, \"Train Top-1-Error\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), validation_acc, \"Validation Top-1-Error\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), train_top5_acc, \"Train Top-5-Error\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), validation_top5_acc, \"Validation Top-5-Error\")\n",
    "]\n",
    "\n",
    "show_plot(plots, \"Model Classification Error for Epoch\", \"Epoch\", \"Error Rate\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MODEL_PATH = './trained_models/resnet18_weights_cars_maker.pth' # TODO: adapt\n",
    "torch.save({\n",
    "    'model_state_dict' : resnet.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'train_acc': train_acc,\n",
    "    'train_top5_acc': train_top5_acc,\n",
    "    'validation_losses': validation_losses,\n",
    "    'validation_acc': validation_acc,\n",
    "    'validation_top5_acc': validation_top5_acc,\n",
    "    'resnet': params['resnet'],\n",
    "    }, MODEL_PATH)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Evaluate Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MODEL_PATH = './trained_models/resnet18_weights_cars_maker.pth'\n",
    "saved_model = torch.load(MODEL_PATH)\n",
    "\n",
    "resnet = ResNet(saved_model['resnet']['block'], saved_model['resnet']['layers'], \n",
    "                len(total_set.classes)).to(params['device'])\n",
    "\n",
    "resnet.load_state_dict(saved_model['model_state_dict'])\n",
    "train_losses = saved_model['train_losses']\n",
    "train_acc = saved_model['train_acc']\n",
    "train_top5_acc = saved_model['train_top5_acc']\n",
    "validation_losses = saved_model['validation_losses']\n",
    "validation_acc = saved_model['validation_acc']\n",
    "validation_top5_acc = saved_model['vaidation_top5_acc']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performance data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plotting the performance of the model in the training and validation phase\n",
    "\n",
    "plots = [\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), train_losses, \"Train Loss\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), validation_losses, \"Validation Loss\")\n",
    "]\n",
    "\n",
    "show_plot(plots, \"Model Loss for Epoch\", \"Epoch\", \"Loss\")\n",
    "\n",
    "plots = [\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), train_acc, \"Train Top-1-Error\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), validation_acc, \"Validation Top-1-Error\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), train_top5_acc, \"Train Top-5-Error\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), validation_top5_acc, \"Validation Top-5-Error\")\n",
    "]\n",
    "\n",
    "show_plot(plots, \"Model Classification Error for Epoch\", \"Epoch\", \"Error Rate\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

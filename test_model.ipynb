{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:13:41.413836Z",
     "start_time": "2024-08-09T17:13:41.410602Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "# from custom files\n",
    "from dataset import CompCarsImageFolder, WrapperDataset, match_class_to_name, match_classes, TestImagesFromTextFile, split_sv_data\n",
    "from resnet import ResNet, resnet_cfg\n",
    "from resnet import test\n",
    "from utils import fix_all_seeds, compute_mean_std_from_dataset"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:13:41.422240Z",
     "start_time": "2024-08-09T17:13:41.415309Z"
    }
   },
   "source": [
    "## Configuration\n",
    "###### Set root to the image folder of CompCars dataset ######\n",
    "\n",
    "### NOTE: ADAPT TO YOUR FOLDER STRUCTURE\n",
    "\n",
    "## EDO'S PATHS\n",
    "root_data = '/Volumes/EDO/NNDL/CompCars dataset/data/image/'\n",
    "root_sv_data = '/Volumes/EDO/NNDL/CompCars dataset/data/sv_data/image/'\n",
    "sv_data_make_model_names = \"/Volumes/EDO/NNDL/CompCars dataset/data/sv_data/sv_make_model_name.txt\"\n",
    "data_make_names = '/Volumes/EDO/NNDL/CompCars dataset/data/sv_data/make_names.txt'\n",
    "data_model_names = '/Volumes/EDO/NNDL/CompCars dataset/data/sv_data/model_names.txt'\n",
    "file = '/Volumes/EDO/NNDL/CompCars dataset/data/sv_data/surveillance.txt'\n",
    "\n",
    "## MICHAEL'S PATHS\n",
    "# root_data = '../cars_data/data/image'\n",
    "# root_sv_data = '../cars_data/sv_data/image'\n",
    "\n",
    "# TODO: add custom test data files (download from WA group)\n",
    "# sv_data_make_model_names = \"../cars_data/sv_data/sv_make_model_name.txt\"\n",
    "# data_make_names = '../cars_data/sv_data/make_names.txt'\n",
    "# data_model_names = '../cars_data/sv_data/model_names.txt'\n",
    "# file = '../cars_data/sv_data/surveillance.txt'\n",
    "\n",
    "#############################################################\n",
    "\n",
    "### Hyperparam configuration\n",
    "resnet_type = 'resnet18'                # 'resnet18', 'resnet34', 'resnet50'    \n",
    "\n",
    "params = {                              ## Test Params\n",
    "    'epoch_num': 50,                    # number of epochs\n",
    "    'batch_size': 128,                  # for test dataloader\n",
    "    'hierarchy': 1,                     # Choose 0 for manufacturer classification, 1 for model classification    \n",
    "    'resnet': resnet_cfg[resnet_type],  # ResNet configuration\n",
    "    'seed': 28,                         # for reproducibility\n",
    "    'supcon': True                      # which algorithm to test\n",
    "}\n",
    "fix_all_seeds(seed=params['seed'])\n",
    "\n",
    "### TODO: Set MODEL_PATH to model you want to test\n",
    "if params['hierarchy'] == 0:\n",
    "    if params['supcon']:\n",
    "        # BUG: fails to load from this model path\n",
    "        MODEL_PATH = './trained_models/lin_moco_resnet18_weights_car_makers_full_dataset_256_nomlp.pth'\n",
    "    else:\n",
    "        MODEL_PATH = './trained_models/resnet18_weights_car_makers_full_dataset_128.pth'\n",
    "else:\n",
    "    if params['supcon']:\n",
    "        # BUG: fails to load from this model path\n",
    "        MODEL_PATH = './trained_models/lin_moco_resnet18_weights_car_models_full_dataset_256_nomlp.pth'\n",
    "    else:\n",
    "        MODEL_PATH = './trained_models/resnet18_weights_car_models_full_dataset_128.pth'\n",
    "    \n",
    "\n",
    "### Device\n",
    "if torch.cuda.is_available():\n",
    "    params[\"device\"] = torch.device(\"cuda\")   # option for NVIDIA GPUs\n",
    "elif torch.backends.mps.is_available():\n",
    "    params[\"device\"] = torch.device(\"mps\")    # option for Mac M-series chips (GPUs)\n",
    "else:\n",
    "    params[\"device\"] = torch.device(\"cpu\")    # default option if none of the above devices are available\n",
    "\n",
    "print(\"Device: {}\".format(params[\"device\"]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model & Test data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:13:43.159307Z",
     "start_time": "2024-08-09T17:13:41.423090Z"
    }
   },
   "source": [
    "## Load full dataset\n",
    "total_set = CompCarsImageFolder(root_data, hierarchy=params['hierarchy'])\n",
    "num_classes = len(total_set.classes)\n",
    "\n",
    "## Load Model\n",
    "saved_model = torch.load(MODEL_PATH, map_location=params['device'])\n",
    "model = ResNet(saved_model['resnet']['block'], saved_model['resnet']['layers'], \n",
    "                num_classes).to(params['device'])\n",
    "model.load_state_dict(saved_model['model_state_dict'])\n",
    "\n",
    "if params['hierarchy'] == 0:\n",
    "    class_names = data_make_names\n",
    "else:\n",
    "    class_names = data_model_names\n",
    "    \n",
    "## Load Test Set\n",
    "matches_classes= match_class_to_name(class_names, total_set.class_to_idx, params['hierarchy'])              # Find actual names of car makers and models\n",
    "sv_data = split_sv_data(sv_data_make_model_names)                                                           # Load and separate surveillance data    \n",
    "test_class_to_idx = match_classes(matches_classes, sv_data, params['hierarchy'])                            # Find the dictionaries of car makers/models present in surveillance data\n",
    "\n",
    "test_set = TestImagesFromTextFile(root_sv_data, \n",
    "                                    sv_data_txt=sv_data_make_model_names, \n",
    "                                    txt_file=file, \n",
    "                                    hierarchy=params['hierarchy'],\n",
    "                                    matches=test_class_to_idx, \n",
    "                                    train_class_to_idx=total_set.class_to_idx)\n",
    "\n",
    "## Normalization\n",
    "\n",
    "# mean, std = [0.483, 0.471, 0.463], [0.297, 0.296, 0.302]                  # default for training and validation data (webbased images)\n",
    "test_mean, test_std = [0.2943, 0.3006, 0.3072], [0.2455, 0.2456, 0.2529]    # default for test data (surveillance data) NOTE: worse results\n",
    "\n",
    "# test_mean, test_std = compute_mean_std_from_dataset(test_set)\n",
    "# print(f\"Test dataset mean: {test_mean}\")\n",
    "# print(f\"Training dataset std: {test_std}\")\n",
    "\n",
    "data_transforms = {\n",
    "    ## Same that is used for validation\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),     # Evaluate using 224x224 central part of image\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(test_mean, test_std)\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "## Prepare test loader\n",
    "wrapped_testset = WrapperDataset(test_set, transform=data_transforms['test'])\n",
    "test_loader = DataLoader(wrapped_testset, batch_size=params['batch_size'], shuffle=False, num_workers=os.cpu_count())"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:15:59.121099Z",
     "start_time": "2024-08-09T17:13:43.160712Z"
    }
   },
   "source": [
    "pbar_inside = trange(0, len(test_loader), desc=\"Test\", bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_inv_fmt}]\")\n",
    "\n",
    "test_results=test(test_loader, model, torch.nn.CrossEntropyLoss(), params[\"device\"], pbar=pbar_inside)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test:   0%|          | 0/348 [00:00<?, ?s/it]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d1ffffb53a8411ea4077757039844c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- TEST --\n",
      "Test results:\n",
      " - Loss: 6.646 +- 0.388\n",
      " - Top-1-Accuracy: 0.17\n",
      " - Top-5-Accuracy: 0.27\n",
      " - Time: 135.95s\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "# from custom files\n",
    "from dataset import CompCarsImageFolder, WrapperDataset, match_class_to_name, match_classes, TestImagesFromTextFile, split_sv_data\n",
    "from models import ResNet, resnet_cfg\n",
    "from models import test\n",
    "from utils import fix_all_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "###### Set root to the image folder of CompCars dataset ######\n",
    "\n",
    "### NOTE: ADAPT TO YOUR FOLDER STRUCTURE\n",
    "\n",
    "## MICHAEL'S PATHS\n",
    "root_data = '../cars_data/data/image'\n",
    "root_sv_data = '../cars_data/sv_data/image'\n",
    "\n",
    "# custom test data files (download from WA group)\n",
    "sv_data_make_model_names = \"../cars_data/sv_data/sv_make_model_name.txt\"\n",
    "data_make_names = '../cars_data/sv_data/make_names.txt'\n",
    "data_model_names = '../cars_data/sv_data/model_names.txt'\n",
    "file = '../cars_data/sv_data/surveillance.txt'\n",
    "\n",
    "#############################################################\n",
    "\n",
    "### Hyperparam configuration\n",
    "resnet_type = 'resnet18'                # 'resnet18', 'resnet34', 'resnet50'    \n",
    "\n",
    "params = {                              ## Test Params\n",
    "    'epoch_num': 50,                    # number of epochs\n",
    "    'batch_size': 128,                  # for test dataloader\n",
    "    'hierarchy': 0,                     # Choose 0 for manufacturer classification, 1 for model classification    \n",
    "    'resnet': resnet_cfg[resnet_type],  # ResNet configuration\n",
    "    'seed': 28,                         # for reproducibility\n",
    "    'supcon': False                     # which algorithm to test\n",
    "}\n",
    "# !!! NOTE: REMEMBER TO PASS SEED TO train_val_dataset FUNCTION AS ARGUMENT !!! \n",
    "fix_all_seeds(seed=params['seed'])\n",
    "\n",
    "### TODO: Set MODEL_PATH to model you want to test\n",
    "if params['hierarchy'] == 0:\n",
    "    if params['supcon']:\n",
    "        MODEL_PATH = './SupCon/trained_models/resnet18_moco_weights_car_makers_full_dataset_256_nomlp_OK.pth'\n",
    "    else:\n",
    "        MODEL_PATH = './trained_models/resnet18_weights_car_makers_full_dataset_128.pth'\n",
    "else:\n",
    "    MODEL_PATH = './trained_models/resnet18_weights_car_models_full_dataset_128.pth'\n",
    "    \n",
    "#############################################################\n",
    "\n",
    "# Augmentation Strategy similar to original ResNet paper: https://arxiv.org/pdf/1512.03385\n",
    "# TODO: CHANGE NORMALIZATION VALUES TO TEST NORMALIZATION VALUES\n",
    "test_mean, test_std = [0.483, 0.471, 0.463], [0.297, 0.296, 0.302]\n",
    "data_transforms = {\n",
    "    ## Same that is used for validation\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),     # Evaluate using 224x224 central part of image\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(test_mean, test_std)\n",
    "    ])\n",
    "}\n",
    "##################################################################\n",
    "\n",
    "### Device\n",
    "if torch.cuda.is_available():\n",
    "    params[\"device\"] = torch.device(\"cuda\")   # option for NVIDIA GPUs\n",
    "elif torch.backends.mps.is_available():\n",
    "    params[\"device\"] = torch.device(\"mps\")    # option for Mac M-series chips (GPUs)\n",
    "else:\n",
    "    params[\"device\"] = torch.device(\"cpu\")    # default option if none of the above devices are available\n",
    "\n",
    "print(\"Device: {}\".format(params[\"device\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model & Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load full dataset\n",
    "total_set = CompCarsImageFolder(root_data, hierarchy=params['hierarchy'])\n",
    "num_classes = len(total_set.classes)\n",
    "\n",
    "## Load Model\n",
    "saved_model = torch.load(MODEL_PATH, map_location=params['device'])\n",
    "resnet = ResNet(saved_model['resnet']['block'], saved_model['resnet']['layers'], \n",
    "                num_classes).to(params['device'])\n",
    "resnet.load_state_dict(saved_model['model_state_dict'])\n",
    "\n",
    "if params['hierarchy'] == 0:\n",
    "    class_names = data_make_names\n",
    "else:\n",
    "    class_names = data_model_names\n",
    "    \n",
    "## Load Test data\n",
    "matches_classes= match_class_to_name(class_names, total_set.class_to_idx, params['hierarchy'])              # Find actual names of car makers and models\n",
    "sv_data = split_sv_data(sv_data_make_model_names)                                                           # Load and separate surveillance data    \n",
    "test_class_to_idx = match_classes(matches_classes, sv_data, params['hierarchy'])                            # Find the dictionaries of car makers/models present in surveillance data\n",
    "\n",
    "test_set = TestImagesFromTextFile(root_sv_data, \n",
    "                                    sv_data_txt=sv_data_make_model_names, \n",
    "                                    txt_file=file, \n",
    "                                    hierarchy=params['hierarchy'],\n",
    "                                    matches=test_class_to_idx, \n",
    "                                    train_class_to_idx=total_set.class_to_idx)\n",
    "\n",
    "wrapped_testset = WrapperDataset(test_set, transform=data_transforms['val'])\n",
    "test_loader = DataLoader(wrapped_testset, batch_size=params['batch_size'], shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results=test(test_loader, resnet, torch.nn.CrossEntropyLoss(), params[\"device\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
